{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from dispel4py.workflow_graph import WorkflowGraph \n",
    "from dispel4py.provenance import *\n",
    "import time\n",
    "import random\n",
    "from dispel4py.base import create_iterative_chain, ConsumerPE, IterativePE, SimpleFunctionPE\n",
    "from clipc_combine_process import clipc_combine_process_d4p\n",
    "from clipc_combine_process import serve_netcdf_d4p\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "\n",
    "# project: CLIP_C\n",
    "# authors: Alessandro and Andrej\n",
    "# CLIPC combine function using dispel4py and running over jupyter\n",
    "# [mihajlov@pc150396 ~]$ .local/bin/jupyter-notebook \n",
    "\n",
    "#print __dir__\n",
    "\n",
    "print \"/usr/people/mihajlov/python/clipc/clipccombine\"\n",
    "print \"CLIPC dispel4py running\"\n",
    "\n",
    "class Collector(GenericPE):\n",
    "        \n",
    "    def __init__(self):\n",
    "        #IterativePE.__init__(self)\n",
    "        GenericPE.__init__(self)\n",
    "        self._add_input('input')\n",
    "        self._add_output('output_R')\n",
    "        #self._add_output('output_W')\n",
    "        self.counter = 0;\n",
    "        \n",
    "    def _process(self,inputs):\n",
    "        print inputs\n",
    "        \n",
    "        url1 = inputs['input'][0]\n",
    "        url2 = inputs['input'][1]\n",
    "     \n",
    "        index = str(self.counter)\n",
    "    \n",
    "        # first  url collected\n",
    "        nc1 = clipc_combine_process_d4p.collect(url1)\n",
    "        self.write('output_R',(  index , 0 , nc1 ))\n",
    "   \n",
    "        #second url collected\n",
    "        #counter = counter + 1\n",
    "        nc2 = clipc_combine_process_d4p.collect(url2)\n",
    "        self.write('output_R',( index , 1 , nc2 ))\n",
    "      \n",
    "        # output written...\n",
    "        nc_out = clipc_combine_process_d4p.write(nc1 , \"d4pout/output\"+index+\".nc\" , \"dr drej n spinuso rock the data flow.\")\n",
    "        \n",
    "        #\n",
    "        self.log(type(nc_out))  \n",
    "        \n",
    "        #\n",
    "        self.write('output_W',( index , nc_out))\n",
    "        \n",
    "        self.counter += 1\n",
    "              \n",
    "    \n",
    "# def readn(data):\n",
    "#     prov={'format':'Random float', 'metadata':{'value':str(data)}}\n",
    "#     return {'_d4p_prov':prov,'_d4p_data':data}\n",
    "        \n",
    "        \n",
    "# def multn(data): \n",
    "#     prov={'format':'Random float', 'metadata':{'value':data*data}}\n",
    "#     print data\n",
    "#     return {'_d4p_prov':prov,'_d4p_data':data*data}\n",
    "\n",
    "    \n",
    "def reader(data):\n",
    "    #nc = clipc_combine_process_d4p.collect(url)\n",
    "    #print \"reader with data:\" , str(data)\n",
    "    \n",
    "    var , norm = clipc_combine_process_d4p.read(data[2])\n",
    "\n",
    "    return ( data[0] , data[1] , var , norm)\n",
    "\n",
    "\n",
    "##################################\n",
    "\n",
    "class Match(GenericPE):\n",
    "\n",
    "    def __init__(self):\n",
    "        GenericPE.__init__(self)\n",
    "        self._add_input('input', grouping=('prov',[0]))\n",
    "        #self._add_input('input2')\n",
    "        self._accumulator = {}\n",
    "        self._add_output('output_X')\n",
    "        \n",
    "    \n",
    "    def _process(self,inputs):\n",
    "        #self.log(  inputs )\n",
    "        \n",
    "        #url1,url2 = inputs['input'][0]\n",
    "        #self._accumulator.append(inputs['input'])\n",
    "        #self._accumulator.append(inputs['input2'])\n",
    "        \n",
    "        inp = inputs['input']\n",
    "        \n",
    "        #print inp[0]\n",
    "        #print inp[1]\n",
    "        #print len(inp[2])                \n",
    "        #print inp[3]\n",
    "        \n",
    "        #inputs(str(0),element,var,norm)\n",
    "        self.log( \"received counter \"+inp[0])\n",
    "        \n",
    "        k = str(inp[0])\n",
    "        if k not in self._accumulator.keys():\n",
    "            self._accumulator[k] = {} \n",
    "        \n",
    "        self._accumulator[k][inp[1]] = ( inp[2] , inp[3] ) \n",
    "        \n",
    "        # if( len(self._accumulator ) == 2 ):\n",
    "        if( len(self._accumulator[str(inp[0])].keys() ) == 2 ):\n",
    "            #combine(self._accumulator)\n",
    "            \n",
    "            output = self._accumulator.pop(k)\n",
    "            \n",
    "            self.write('output_X', (k , output[0] , output[1]) )\n",
    "\n",
    "            #print self._accumulator[k].keys()\n",
    "            \n",
    "        #nc1 = clipc_combine_process_d4p.collect(url1)\n",
    "        #self.write('output_R',nc1)\n",
    "   \n",
    "        #nc_out = clipc_combine_process_d4p.write(nc1 , \"output.nc\" , \"dr drej n spinuso rock the data flow.\")\n",
    "        #self.write('output_W',nc_out)\n",
    "        \n",
    "        #nc2 = clipc_combine_process_d4p.collect(url2)\n",
    "        #self.write('output_R',nc2)\n",
    "        \n",
    "def combine(data,operator):\n",
    "    comb_var = clipc_combine_process_d4p.combine( data[1][0] , data[1][1] , data[2][0] , data[2][1] , operator)\n",
    "    \n",
    "    return ( data[0] , comb_var)\n",
    "\n",
    "\n",
    "    \n",
    "class Writer(GenericPE):\n",
    "\n",
    "    def __init__(self,op):\n",
    "        GenericPE.__init__(self)\n",
    "        self._add_input('file' , grouping=('prov',[0]))\n",
    "        self._add_input('var'  , grouping=('prov',[0]))\n",
    "        self._opp = op\n",
    "        self._accumulator = []\n",
    "        self._add_output('final')\n",
    "        \n",
    "        # index hash\n",
    "        self.file = {}\n",
    "        self.var  = {}\n",
    "        \n",
    "    def _process(self,inputs):\n",
    "        self.log(str(inputs))\n",
    "      \n",
    "        index = None\n",
    "        \n",
    "        try:\n",
    "            if 'file' in inputs:\n",
    "                f = inputs['file']\n",
    "                index = f[0]\n",
    "                self.file[index]=f[1]\n",
    "            elif 'var' in inputs:\n",
    "                v = inputs['var']   \n",
    "                index = v[0]\n",
    "                self.var[index]=v[1]\n",
    "\n",
    "            self.log(\"index writen:\"+index)      \n",
    "        except:\n",
    "            print \"exception for writer input: \" , index \n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            if (self.var[index] != None and self.file[index] != None):\n",
    "                x=clipc_combine_process_d4p.postprocess(self.var.pop(index),self.file.pop(index))\n",
    "                self.write('final',x[0])\n",
    "        except:\n",
    "            print \"andrej exception send \" , index , \" in \" , self.file.keys() , self.var.keys()\n",
    "            #traceback.print_stack()\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "            \n",
    "class Visualiser(GenericPE):\n",
    "\n",
    "    def __init__(self):\n",
    "        GenericPE.__init__(self)\n",
    "        self._add_input('input')\n",
    "        self._add_input('res')\n",
    "        #self._accumulator = []\n",
    "        #self.plot\n",
    "    \n",
    "    def _process(self,inputs):\n",
    "        #print inputs\n",
    "        \n",
    "        #self._accumulator.append(inputs['input'])\n",
    "        fig = plt.figure(1)\n",
    "        \n",
    "        serve_netcdf_d4p.visualise1(fig, inputs['input']  )\n",
    "        \n",
    "        self.write('res',{})\n",
    "    \n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sc1 = Collector()\n",
    "sc1.name = 'collector'\n",
    "\n",
    "sc2 = Match()\n",
    "sc2.name = 'match'\n",
    "\n",
    "sc3 = Writer(\"+\")\n",
    "sc3.name = 'writer'\n",
    "\n",
    "sc4 = Visualiser()\n",
    "sc4.name = 'vizu'\n",
    "\n",
    "read=SimpleFunctionPE(reader)\n",
    "comb=SimpleFunctionPE(combine,{\"operator\":\"+\"})\n",
    " \n",
    "\n",
    "#processes=[readn,multn]\n",
    "#chain = create_iterative_chain(processes, FunctionPE_class=SimpleFunctionPE)\n",
    "\n",
    "#Initialise the graph\n",
    "graph = WorkflowGraph()\n",
    "\n",
    "#Common way of composing the graph\n",
    "graph.connect(sc1,'output_R',read,'input')\n",
    "graph.connect(read,'output', sc2,'input')\n",
    "graph.connect(sc2,'output_X',comb,'input')\n",
    "graph.connect(comb,'output',sc3,'var')\n",
    "graph.connect(sc1,'output_W',sc3,'file')\n",
    "graph.connect(sc3,'final',sc4,'input')\n",
    "\n",
    "# Alternatively with pipeline array\n",
    "#Create pipelines from functions\n",
    "\n",
    "#graph.connect(sc,'output',chain,'input')\n",
    "\n",
    "\n",
    "\n",
    "graph.flatten()\n",
    "\n",
    "\n",
    "# /usr/people/mihajlov/python/clipc/clipccombine/clipc_combine_process\n",
    "# file running: combine_netcdf.py\n",
    "# def combine_two_indecies(url1,url2,operation,output,...):\n",
    "\n",
    "\n",
    "#Prepare Input\n",
    "url1 = 'example/vDTR_JUN_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_SMHI-RCA4_v1_EUR-11_2006-2100.nc'\n",
    "url2 = 'example/vDTR_OCT_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_SMHI-RCA4_v1_EUR-11_2006-2100.nc'\n",
    "\n",
    "input_data = {\"collector\": [{\"input\": [url1,url2]},{\"input\": [url1,url2]},{\"input\": [url1,url2] }]}\n",
    "\n",
    "print 'inputs.clipc'                                                     \n",
    "print input_data                   \n",
    "                                                     \n",
    "#Launch in simple process\n",
    "simple_process.process_and_return(graph, input_data)\n",
    "\n",
    "\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "ProvenanceRecorderToServiceBulk.REPOS_URL='http://verce-portal-dev.scai.fraunhofer.de/j2ep-1.0/prov/workflow/insert'\n",
    "rid='RDWD_'+getUniqueId()\n",
    "InitiateNewRun(graph,ProvenanceRecorderToServiceBulk,provImpClass=ProvenancePE,username='aspinuso',runId=rid,w3c_prov=False,workflowName=\"test_rdwd\",workflowId=\"xx\")\n",
    "\n",
    "simple_process.process_and_return(graph, input_data)\n",
    "\n",
    "#plt.show()\n",
    "#from IPython.display import HTML\n",
    "#HTML(\"<iframe src='http://127.0.01:8080/provenance-explorer/html/d3js.jsp?level=PE&runId=\"+rid+\"' width=800 height=800></iframe>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dispel4py.visualisation import display\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ProvenanceRecorderToServiceBulk.REPOS_URL='http://verce-portal-dev.scai.fraunhofer.de/j2ep-1.0/prov/workflow/insert'\n",
    "rid='RDWD_'+getUniqueId()\n",
    "#InitiateNewRun(graph,ProvenanceRecorderToServiceBulk,provImpClass=ProvenancePE,username='aspinuso',runId=rid,w3c_prov=False,workflowName=\"test_rdwd\",workflowId=\"xx\")\n",
    "\n",
    "extra_args=['-n', '3']\n",
    "dispel4py.new.processor.process_and_return(graph, input_data, 'multi',extra_args)\n",
    "\n",
    "\n",
    "\n",
    "#from IPython.display import HTML\n",
    "#HTML(\"<iframe src='http://127.0.01:8080/provenance-explorer/html/d3js.jsp?level=instances&runId=\"+rid+\"' width=800 height=800></iframe>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dispel4py.visualisation import display\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
